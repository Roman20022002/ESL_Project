{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors  import NearestCentroid\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Linear Models\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Linear & Quadratic Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, CategoricalNB\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Additional\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data.csv\"\n",
    "data = pd.read_csv(file_path, delimiter=\";\")\n",
    "data = data[data['Target'] != 'Enrolled'] #only considering 'Dropout' and 'Graduate'\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_columns = data.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "categorical_columns = [\"Marital status\", \"Daytime/evening attendance\\t\", \"Gender\", \"Target\"]\n",
    "# Remove categorical columns from numerical processing\n",
    "numerical_columns = [col for col in numerical_columns if col not in categorical_columns]\n",
    "\n",
    "# Handle outliers in numerical columns using z-score (capping values beyond 3 standard deviations)\n",
    "data[numerical_columns] = data[numerical_columns].apply(\n",
    "    lambda x: x.clip(lower=x.mean() - 3 * x.std(), upper=x.mean() + 3 * x.std())\n",
    ")\n",
    "\n",
    "# Encoding categorical variables\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_columns[:-1], drop_first=True)\n",
    "\n",
    "# Standardize numerical columns for consistency across all classifiers\n",
    "scaler = StandardScaler()\n",
    "data_encoded[numerical_columns] = scaler.fit_transform(data_encoded[numerical_columns])\n",
    "\n",
    "target_mapping = {0: \"Dropout\", 1: \"Graduate\"}\n",
    "# Apply PCA to retain 95% of variance\n",
    "X = data_encoded.drop(columns=[\"Target\"])\n",
    "y = data_encoded[\"Target\"]\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.78it/s]\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"SVC\": SVC(probability=True), #enable probability estimates for SVC\n",
    "\n",
    "    \"LinearDiscriminant\": LinearDiscriminantAnalysis(),\n",
    "    \"QuadraticDiscriminant\": QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "\n",
    "    \"LogisticRegression\": LogisticRegression(multi_class=\"multinomial\", max_iter=500),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y) #for having same proportions of each class through folds (dataset unbalanced!)\n",
    "results = []\n",
    "\n",
    "tqdm_iter = tqdm(classifiers.items())\n",
    "for clf_name, clf in tqdm_iter:\n",
    "\n",
    "    if not hasattr(clf, \"predict_proba\"):\n",
    "        clf = CalibratedClassifierCV(clf)\n",
    "    \n",
    "    probs = cross_val_predict(clf, X_test, y_test, cv=5, method='predict_proba')\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    max_probs = np.max(probs, axis=1)\n",
    "    \n",
    "    for i, (pred, prob) in enumerate(zip(preds, max_probs)):\n",
    "\n",
    "        if len(results) <= i:\n",
    "\n",
    "            results.append({})\n",
    "        label = target_mapping[pred]\n",
    "        results[i][f\"{clf_name}_Label\"] = label\n",
    "        results[i][f\"{clf_name}_ProbScore\"] = prob\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Add true labels \n",
    "results_df[\"True_Label\"] = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kNN_Label</th>\n",
       "      <th>kNN_ProbScore</th>\n",
       "      <th>DecisionTree_Label</th>\n",
       "      <th>DecisionTree_ProbScore</th>\n",
       "      <th>SVC_Label</th>\n",
       "      <th>SVC_ProbScore</th>\n",
       "      <th>LinearDiscriminant_Label</th>\n",
       "      <th>LinearDiscriminant_ProbScore</th>\n",
       "      <th>QuadraticDiscriminant_Label</th>\n",
       "      <th>QuadraticDiscriminant_ProbScore</th>\n",
       "      <th>...</th>\n",
       "      <th>GaussianNB_ProbScore</th>\n",
       "      <th>LogisticRegression_Label</th>\n",
       "      <th>LogisticRegression_ProbScore</th>\n",
       "      <th>RandomForest_Label</th>\n",
       "      <th>RandomForest_ProbScore</th>\n",
       "      <th>Bagging_Label</th>\n",
       "      <th>Bagging_ProbScore</th>\n",
       "      <th>AdaBoost_Label</th>\n",
       "      <th>AdaBoost_ProbScore</th>\n",
       "      <th>True_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.510454</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.852367</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.999081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993331</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.662619</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.57</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.529478</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.941331</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.986785</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861029</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.941335</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.77</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.604695</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.922043</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.990851</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991078</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.977961</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.592476</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.929558</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.980752</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.998666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986587</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.932972</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.76</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.606583</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.970810</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.995383</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997634</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.983171</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.604020</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  kNN_Label  kNN_ProbScore DecisionTree_Label  DecisionTree_ProbScore  \\\n",
       "0  Graduate            0.6           Graduate                     1.0   \n",
       "1  Graduate            1.0           Graduate                     1.0   \n",
       "2  Graduate            1.0           Graduate                     1.0   \n",
       "3  Graduate            0.8           Graduate                     1.0   \n",
       "4  Graduate            0.6           Graduate                     1.0   \n",
       "\n",
       "  SVC_Label  SVC_ProbScore LinearDiscriminant_Label  \\\n",
       "0  Graduate       0.510454                 Graduate   \n",
       "1  Graduate       0.941331                 Graduate   \n",
       "2  Graduate       0.922043                 Graduate   \n",
       "3  Graduate       0.929558                 Graduate   \n",
       "4  Graduate       0.970810                 Graduate   \n",
       "\n",
       "   LinearDiscriminant_ProbScore QuadraticDiscriminant_Label  \\\n",
       "0                      0.852367                     Dropout   \n",
       "1                      0.986785                    Graduate   \n",
       "2                      0.990851                    Graduate   \n",
       "3                      0.980752                    Graduate   \n",
       "4                      0.995383                    Graduate   \n",
       "\n",
       "   QuadraticDiscriminant_ProbScore  ... GaussianNB_ProbScore  \\\n",
       "0                         0.999081  ...             0.993331   \n",
       "1                         1.000000  ...             0.861029   \n",
       "2                         0.999999  ...             0.991078   \n",
       "3                         0.998666  ...             0.986587   \n",
       "4                         1.000000  ...             0.997634   \n",
       "\n",
       "   LogisticRegression_Label LogisticRegression_ProbScore  RandomForest_Label  \\\n",
       "0                  Graduate                     0.662619             Dropout   \n",
       "1                  Graduate                     0.941335            Graduate   \n",
       "2                  Graduate                     0.977961            Graduate   \n",
       "3                  Graduate                     0.932972            Graduate   \n",
       "4                  Graduate                     0.983171            Graduate   \n",
       "\n",
       "  RandomForest_ProbScore  Bagging_Label Bagging_ProbScore  AdaBoost_Label  \\\n",
       "0                   0.57       Graduate               0.8        Graduate   \n",
       "1                   0.77       Graduate               0.7        Graduate   \n",
       "2                   0.79       Graduate               0.9        Graduate   \n",
       "3                   0.76       Graduate               1.0        Graduate   \n",
       "4                   0.92       Graduate               1.0        Graduate   \n",
       "\n",
       "  AdaBoost_ProbScore  True_Label  \n",
       "0           0.529478     Dropout  \n",
       "1           0.604695    Graduate  \n",
       "2           0.592476    Graduate  \n",
       "3           0.606583    Graduate  \n",
       "4           0.604020    Graduate  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726\n"
     ]
    }
   ],
   "source": [
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graduate: 442\n",
      "Dropout: 284\n"
     ]
    }
   ],
   "source": [
    "label_counts = pd.Series(y_test).value_counts()\n",
    "\n",
    "print(f\"Graduate: {label_counts.get('Graduate', 0)}\")\n",
    "print(f\"Dropout: {label_counts.get('Dropout', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN: 122 mismatches\n",
      "DecisionTree: 160 mismatches\n",
      "SVC: 94 mismatches\n",
      "LinearDiscriminant: 88 mismatches\n",
      "QuadraticDiscriminant: 108 mismatches\n",
      "GaussianNB: 145 mismatches\n",
      "LogisticRegression: 84 mismatches\n",
      "RandomForest: 91 mismatches\n",
      "Bagging: 105 mismatches\n",
      "AdaBoost: 110 mismatches\n"
     ]
    }
   ],
   "source": [
    "mismatch_counts = {}\n",
    "\n",
    "for clf_name in classifiers.keys():\n",
    "\n",
    "    mismatch_counts[clf_name] = results_df.apply(\n",
    "        lambda row: row[f\"{clf_name}_Label\"] != row[\"True_Label\"] \n",
    "        if pd.notna(row[f\"{clf_name}_Label\"]) else False, \n",
    "        axis=1\n",
    "    ).sum()\n",
    "\n",
    "for clf_name, count in mismatch_counts.items():\n",
    "    \n",
    "    print(f\"{clf_name}: {count} mismatches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for kNN: 0.86 (+/- 0.00)\n",
      "Accuracy for DecisionTree: 0.85 (+/- 0.01)\n",
      "Accuracy for SVC: 0.91 (+/- 0.01)\n",
      "Accuracy for NearestCentroid: 0.86 (+/- 0.00)\n",
      "Accuracy for LinearDiscriminant: 0.90 (+/- 0.01)\n",
      "Accuracy for QuadraticDiscriminant: 0.85 (+/- 0.01)\n",
      "Accuracy for GaussianNB: 0.82 (+/- 0.01)\n",
      "Accuracy for GradientBoosting: 0.91 (+/- 0.00)\n",
      "Accuracy for LogisticRegression: 0.91 (+/- 0.01)\n",
      "Accuracy for RandomForest: 0.91 (+/- 0.00)\n",
      "Accuracy for Bagging: 0.89 (+/- 0.01)\n",
      "Accuracy for AdaBoost: 0.90 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "#Results of individual classifiers\n",
    "classifiers = {\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"SVC\": SVC(probability=True), #enable probability estimates for SVC\n",
    "    \"NearestCentroid\": NearestCentroid(),\n",
    "    \"LinearDiscriminant\": LinearDiscriminantAnalysis(),\n",
    "    \"QuadraticDiscriminant\": QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(multi_class=\"multinomial\", max_iter=500),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "}\n",
    "warnings.simplefilter('ignore')\n",
    "for clf_name, clf in classifiers.items():\n",
    "    scores = model_selection.cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy for %s: %0.2f (+/- %0.2f)\" \n",
    "          % (clf_name, scores.mean(), scores.std() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data.csv\"\n",
    "data = pd.read_csv(file_path, delimiter=\";\")\n",
    "data = data[data['Target'] != 'Enrolled'] #only considering 'Dropout' and 'Graduate'\n",
    "\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_columns = data.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "categorical_columns = [\"Marital status\", \"Daytime/evening attendance\\t\", \"Gender\", \"Target\"]\n",
    "\n",
    "# Handle outliers in numerical columns using z-score (capping values beyond 3 standard deviations)\n",
    "numerical_columns = [col for col in numerical_columns if col not in categorical_columns]\n",
    "data[numerical_columns] = data[numerical_columns].apply(\n",
    "    lambda x: x.clip(lower=x.mean() - 3 * x.std(), upper=x.mean() + 3 * x.std())\n",
    ") #column-wise\n",
    "\n",
    "# Encoding categorical variables\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_columns[:-1], drop_first=True)\n",
    "\n",
    "# Standardize numerical columns for consistency across all classifiers\n",
    "scaler = StandardScaler()\n",
    "data_encoded[numerical_columns] = scaler.fit_transform(data_encoded[numerical_columns])\n",
    "\n",
    "# Apply PCA to retain 95% of variance\n",
    "X = data_encoded.drop(columns=[\"Target\"])\n",
    "y = data_encoded[\"Target\"]\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y) #for having same proportions of each class through folds (dataset unbalanced!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  11%|█         | 2/18 [00:00<00:02,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for LogisticRegression: 0.94 (+/- 0.01)\n",
      "Accuracy for RidgeClassifier: 0.94 (+/- 0.00)\n",
      "Accuracy for LinearDiscriminantAnalysis: 0.94 (+/- 0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  22%|██▏       | 4/18 [00:00<00:01,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for ShrinkageLDA: 0.94 (+/- 0.00)\n",
      "Accuracy for QuadraticDiscriminantAnalysis: 0.91 (+/- 0.00)\n",
      "Accuracy for RegularizedQDA: 0.90 (+/- 0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  39%|███▉      | 7/18 [00:00<00:01,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for LinearSVC: 0.94 (+/- 0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  44%|████▍     | 8/18 [00:07<00:15,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SVC_rbf: 0.95 (+/- 0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  56%|█████▌    | 10/18 [00:08<00:07,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for HingeSGDClassifier: 0.94 (+/- 0.01)\n",
      "Accuracy for LogLossSGDClassifier: 0.93 (+/- 0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  61%|██████    | 11/18 [00:09<00:08,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for PolynomialSGDClassifier: 0.90 (+/- 0.01)\n",
      "Accuracy for GaussianNB: 0.86 (+/- 0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  72%|███████▏  | 13/18 [00:10<00:03,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for DecisionTreeClassifier: 0.76 (+/- 0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  78%|███████▊  | 14/18 [00:10<00:02,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for FullDecisionTreeClassifier: 0.82 (+/- 0.02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  83%|████████▎ | 15/18 [00:14<00:04,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for RandomForestClassifier: 0.93 (+/- 0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  89%|████████▉ | 16/18 [00:14<00:02,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KNeighborsClassifier: 0.91 (+/- 0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers:  94%|█████████▍| 17/18 [00:21<00:02,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for BaggingClassifier: 0.93 (+/- 0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Individual Classifiers: 100%|██████████| 18/18 [00:31<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for AdaBoostClassifier: 0.93 (+/- 0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations: 100%|██████████| 153/153 [17:42<00:00,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Combined Models  \\\n",
      "0                 LogisticRegression + RidgeClassifier   \n",
      "1      LogisticRegression + LinearDiscriminantAnalysis   \n",
      "2                    LogisticRegression + ShrinkageLDA   \n",
      "3    LogisticRegression + QuadraticDiscriminantAnal...   \n",
      "4                  LogisticRegression + RegularizedQDA   \n",
      "..                                                 ...   \n",
      "148         RandomForestClassifier + BaggingClassifier   \n",
      "149        RandomForestClassifier + AdaBoostClassifier   \n",
      "150           KNeighborsClassifier + BaggingClassifier   \n",
      "151          KNeighborsClassifier + AdaBoostClassifier   \n",
      "152             BaggingClassifier + AdaBoostClassifier   \n",
      "\n",
      "         Individual Model 1             Individual Model 2  Combined Accuracy  \\\n",
      "0        LogisticRegression                RidgeClassifier           0.942194   \n",
      "1        LogisticRegression     LinearDiscriminantAnalysis           0.941650   \n",
      "2        LogisticRegression                   ShrinkageLDA           0.941828   \n",
      "3        LogisticRegression  QuadraticDiscriminantAnalysis           0.941683   \n",
      "4        LogisticRegression                 RegularizedQDA           0.941375   \n",
      "..                      ...                            ...                ...   \n",
      "148  RandomForestClassifier              BaggingClassifier           0.933022   \n",
      "149  RandomForestClassifier             AdaBoostClassifier           0.935461   \n",
      "150    KNeighborsClassifier              BaggingClassifier           0.924460   \n",
      "151    KNeighborsClassifier             AdaBoostClassifier           0.928904   \n",
      "152       BaggingClassifier             AdaBoostClassifier           0.929933   \n",
      "\n",
      "     Best Individual Accuracy  Difference  Std Dev (Combined)  \n",
      "0                    0.941288    0.000907            0.004560  \n",
      "1                    0.941288    0.000362            0.004873  \n",
      "2                    0.941288    0.000540            0.004690  \n",
      "3                    0.941288    0.000395            0.005080  \n",
      "4                    0.941288    0.000088            0.005240  \n",
      "..                        ...         ...                 ...  \n",
      "148                  0.934374   -0.001351            0.004546  \n",
      "149                  0.934374    0.001088            0.003855  \n",
      "150                  0.928303   -0.003843            0.004006  \n",
      "151                  0.930184   -0.001279            0.002850  \n",
      "152                  0.930184   -0.000250            0.004744  \n",
      "\n",
      "[153 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"RidgeClassifier\": RidgeClassifier(), \n",
    "\n",
    "    \"LinearDiscriminantAnalysis\": LinearDiscriminantAnalysis(),\n",
    "    \"ShrinkageLDA\": LinearDiscriminantAnalysis(solver=\"lsqr\", shrinkage=\"auto\"), \n",
    "    \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"RegularizedQDA\": QuadraticDiscriminantAnalysis(reg_param=0.5), #reg points? \n",
    "\n",
    "    \"LinearSVC\": LinearSVC(),\n",
    "    \"SVC_rbf\": SVC(kernel='rbf', probability=True), \n",
    "\n",
    "    \"HingeSGDClassifier\": SGDClassifier(loss='hinge'),\n",
    "    \"LogLossSGDClassifier\": SGDClassifier(loss='log_loss'),\n",
    "    \"PolynomialSGDClassifier\": make_pipeline(PolynomialFeatures(), SGDClassifier()), \n",
    "\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    #\"MultinomialNB\": MultinomialNB(), different data scale --> different train/test sets\n",
    "    #\"ComplementNB\": ComplementNB(), \n",
    "    #\"CategoricalNB\": CategoricalNB(), \n",
    "\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=1),\n",
    "    \"FullDecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"BaggingClassifier\": BaggingClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier()\n",
    "}\n",
    "# Classifiers needing calibration due to unreliable probabilities\n",
    "requires_calibration = {\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"KNeighborsClassifier\",\n",
    "    \"SVC_rbf\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"BaggingClassifier\"   \n",
    "}\n",
    "\n",
    "def indiv():\n",
    "    results = {}  # Dictionary to store classifier results\n",
    "    tqdm_iter = tqdm(classifiers.items(), desc=\"Processing Individual Classifiers\")\n",
    "\n",
    "    for clf_name, clf in tqdm_iter:\n",
    "        if not hasattr(clf, \"predict_proba\") or clf_name in requires_calibration:\n",
    "            clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "        \n",
    "        scores = cross_val_score(clf, X_pca, y, cv=5, scoring='roc_auc')\n",
    "        print(\"Accuracy for %s: %0.2f (+/- %0.2f)\" \n",
    "              % (clf_name, scores.mean(), scores.std()))\n",
    "\n",
    "        # Store results in the dictionary\n",
    "        results[clf_name] = (scores.mean(), scores.std())\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "def combine():\n",
    "    combinations = itertools.combinations(classifiers.items(), 2)\n",
    "    total_combinations = len(list(itertools.combinations(classifiers.items(), 2)))\n",
    "    tqdm_iter = tqdm(combinations, total=total_combinations, desc=\"Processing combinations\")\n",
    "    results = []\n",
    "\n",
    "    for combo in tqdm_iter:\n",
    "        base_classifiers = [(name, clf) for name, clf in combo]\n",
    "        #used only logistic for now, can chec other meta-classifiers\n",
    "        meta_classifier = LogisticRegression()\n",
    "\n",
    "        stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=meta_classifier)\n",
    "\n",
    "\n",
    "        stacking_clf.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = stacking_clf.predict(X_test)\n",
    "        scores = model_selection.cross_val_score(stacking_clf, X_pca, y, cv=5, scoring='roc_auc')\n",
    "        accuracy = scores.mean()\n",
    "        std_dev = scores.std()\n",
    "\n",
    "        results.append((base_classifiers, accuracy, std_dev))\n",
    "    return results\n",
    "\n",
    "# Step 1: Calculate individual model accuracies\n",
    "individual_accuracies = indiv()\n",
    "\n",
    "# Step 2: Calculate combination model accuracies\n",
    "combination_results = combine()\n",
    "\n",
    "# Step 3: Build the comparison table\n",
    "comparison_table = []\n",
    "\n",
    "for base_classifiers, comb_accuracy, comb_std_dev in combination_results:\n",
    "    clf1_name, clf2_name = [name for name, _ in base_classifiers]\n",
    "    clf1_accuracy = individual_accuracies[clf1_name][0]\n",
    "    clf2_accuracy = individual_accuracies[clf2_name][0]\n",
    "    best_individual_accuracy = max(clf1_accuracy, clf2_accuracy)\n",
    "    difference = comb_accuracy - best_individual_accuracy\n",
    "\n",
    "    comparison_table.append({\n",
    "        \"Combined Models\": f\"{clf1_name} + {clf2_name}\",\n",
    "        \"Individual Model 1\": clf1_name,\n",
    "        \"Individual Model 2\": clf2_name,\n",
    "        \"Combined Accuracy\": comb_accuracy,\n",
    "        \"Best Individual Accuracy\": best_individual_accuracy,\n",
    "        \"Difference\": difference,\n",
    "        \"Std Dev (Combined)\": comb_std_dev\n",
    "    })\n",
    "\n",
    "# Step 4: Create and display the DataFrame\n",
    "results_df = pd.DataFrame(comparison_table)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results_table_last.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Stacking Classifier: 0.91 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "#some checkings\n",
    "meta_classifier = LogisticRegression()\n",
    "base_classifier1 = [\n",
    "    ('SVC', classifiers[\"SVC\"]),\n",
    "    ('LogisticRegression', classifiers[\"LogisticRegression\"]),\n",
    "    ('RandomForest', classifiers[\"RandomForest\"]),\n",
    "    ]\n",
    "base_classifier2 = [\n",
    "    ('GradientBoostingClassifier', classifiers[\"GradientBoosting\"]),\n",
    "    (\"kNN\", classifiers[\"kNN\"]),\n",
    "    (\"GaussianNB\", classifiers[\"GaussianNB\"]),\n",
    "    ]\n",
    "base_classifier3 = [\n",
    "    ('SVC', classifiers[\"SVC\"]),\n",
    "    (\"LinearDiscriminant\", classifiers[\"LinearDiscriminant\"]),\n",
    "    ('AdaBoost', classifiers[\"AdaBoost\"]),\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_classifier3, final_estimator=meta_classifier)\n",
    "# Train stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "scores = model_selection.cross_val_score(stacking_clf , X, y, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy for Stacking Classifier: %0.2f (+/- %0.2f)\" \n",
    "          % (scores.mean(), scores.std() ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
