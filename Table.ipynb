{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data.csv\"\n",
    "data = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_columns = data.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "categorical_columns = [\"Marital status\", \"Daytime/evening attendance\\t\", \"Gender\", \"Target\"]\n",
    "# Remove categorical columns from numerical processing\n",
    "numerical_columns = [col for col in numerical_columns if col not in categorical_columns]\n",
    "\n",
    "# Handle outliers in numerical columns using z-score (capping values beyond 3 standard deviations)\n",
    "data[numerical_columns] = data[numerical_columns].apply(\n",
    "    lambda x: x.clip(lower=x.mean() - 3 * x.std(), upper=x.mean() + 3 * x.std())\n",
    ")\n",
    "\n",
    "# Encoding categorical variables\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_columns[:-1], drop_first=True)\n",
    "\n",
    "# Standardize numerical columns for consistency across all classifiers\n",
    "scaler = StandardScaler()\n",
    "data_encoded[numerical_columns] = scaler.fit_transform(data_encoded[numerical_columns])\n",
    "\n",
    "target_mapping = {0: \"Dropout\", 1: \"Enrolled\", 2: \"Graduate\"}\n",
    "# Apply PCA to retain 95% of variance\n",
    "X = data_encoded.drop(columns=[\"Target\"])\n",
    "y = data_encoded[\"Target\"]\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"SVC\": SVC(probability=True), #enable probability estimates for SVC\n",
    "\n",
    "    \"LinearDiscriminant\": LinearDiscriminantAnalysis(),\n",
    "    \"QuadraticDiscriminant\": QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "\n",
    "    \"LogisticRegression\": LogisticRegression(multi_class=\"multinomial\", max_iter=500),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y) #for having same proportions of each class through folds (dataset unbalanced!)\n",
    "results = []\n",
    "\n",
    "tqdm_iter = tqdm(classifiers.items())\n",
    "for clf_name, clf in tqdm_iter:\n",
    "\n",
    "    if not hasattr(clf, \"predict_proba\"):\n",
    "        clf = CalibratedClassifierCV(clf)\n",
    "    \n",
    "    probs = cross_val_predict(clf, X_test, y_test, cv=5, method='predict_proba')\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    max_probs = np.max(probs, axis=1)\n",
    "    \n",
    "    for i, (pred, prob) in enumerate(zip(preds, max_probs)):\n",
    "\n",
    "        if len(results) <= i:\n",
    "\n",
    "            results.append({})\n",
    "        label = target_mapping[pred]\n",
    "        if label == \"Enrolled\":\n",
    "\n",
    "            results[i][f\"{clf_name}_Label\"] = np.nan\n",
    "            results[i][f\"{clf_name}_ProbScore\"] = np.nan\n",
    "        else:\n",
    "\n",
    "            results[i][f\"{clf_name}_Label\"] = label\n",
    "            results[i][f\"{clf_name}_ProbScore\"] = prob\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Add true labels \n",
    "results_df[\"True_Label\"] = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kNN_Label</th>\n",
       "      <th>kNN_ProbScore</th>\n",
       "      <th>DecisionTree_Label</th>\n",
       "      <th>DecisionTree_ProbScore</th>\n",
       "      <th>SVC_Label</th>\n",
       "      <th>SVC_ProbScore</th>\n",
       "      <th>LinearDiscriminant_Label</th>\n",
       "      <th>LinearDiscriminant_ProbScore</th>\n",
       "      <th>QuadraticDiscriminant_Label</th>\n",
       "      <th>QuadraticDiscriminant_ProbScore</th>\n",
       "      <th>...</th>\n",
       "      <th>GaussianNB_ProbScore</th>\n",
       "      <th>LogisticRegression_Label</th>\n",
       "      <th>LogisticRegression_ProbScore</th>\n",
       "      <th>RandomForest_Label</th>\n",
       "      <th>RandomForest_ProbScore</th>\n",
       "      <th>Bagging_Label</th>\n",
       "      <th>Bagging_ProbScore</th>\n",
       "      <th>AdaBoost_Label</th>\n",
       "      <th>AdaBoost_ProbScore</th>\n",
       "      <th>True_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.879428</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.867365</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.996525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911931</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.856286</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.68</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.360882</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.789532</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.760473</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.959568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894778</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.655494</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.351642</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.663856</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.675671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.699086</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.361247</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.952936</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.953419</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.992552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956069</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.933668</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.82</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.357666</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.915668</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.906672</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.912792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853458</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.818331</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.72</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.348888</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  kNN_Label  kNN_ProbScore DecisionTree_Label  DecisionTree_ProbScore  \\\n",
       "0  Graduate            0.8            Dropout                     1.0   \n",
       "1  Graduate            0.8           Graduate                     1.0   \n",
       "2   Dropout            0.4                NaN                     NaN   \n",
       "3  Graduate            1.0           Graduate                     1.0   \n",
       "4  Graduate            0.8           Graduate                     1.0   \n",
       "\n",
       "  SVC_Label  SVC_ProbScore LinearDiscriminant_Label  \\\n",
       "0  Graduate       0.879428                 Graduate   \n",
       "1  Graduate       0.789532                 Graduate   \n",
       "2   Dropout       0.663856                  Dropout   \n",
       "3  Graduate       0.952936                 Graduate   \n",
       "4  Graduate       0.915668                 Graduate   \n",
       "\n",
       "   LinearDiscriminant_ProbScore QuadraticDiscriminant_Label  \\\n",
       "0                      0.867365                    Graduate   \n",
       "1                      0.760473                    Graduate   \n",
       "2                      0.675671                         NaN   \n",
       "3                      0.953419                    Graduate   \n",
       "4                      0.906672                    Graduate   \n",
       "\n",
       "   QuadraticDiscriminant_ProbScore  ... GaussianNB_ProbScore  \\\n",
       "0                         0.996525  ...             0.911931   \n",
       "1                         0.959568  ...             0.894778   \n",
       "2                              NaN  ...                  NaN   \n",
       "3                         0.992552  ...             0.956069   \n",
       "4                         0.912792  ...             0.853458   \n",
       "\n",
       "   LogisticRegression_Label LogisticRegression_ProbScore  RandomForest_Label  \\\n",
       "0                  Graduate                     0.856286            Graduate   \n",
       "1                  Graduate                     0.655494            Graduate   \n",
       "2                   Dropout                     0.699086             Dropout   \n",
       "3                  Graduate                     0.933668            Graduate   \n",
       "4                  Graduate                     0.818331            Graduate   \n",
       "\n",
       "  RandomForest_ProbScore  Bagging_Label Bagging_ProbScore  AdaBoost_Label  \\\n",
       "0                   0.68       Graduate               0.6        Graduate   \n",
       "1                   0.75       Graduate               0.9        Graduate   \n",
       "2                   0.58        Dropout               0.8         Dropout   \n",
       "3                   0.82       Graduate               0.6        Graduate   \n",
       "4                   0.72       Graduate               0.8        Graduate   \n",
       "\n",
       "  AdaBoost_ProbScore  True_Label  \n",
       "0           0.360882    Graduate  \n",
       "1           0.351642    Graduate  \n",
       "2           0.361247    Enrolled  \n",
       "3           0.357666    Graduate  \n",
       "4           0.348888    Graduate  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
