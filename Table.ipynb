{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data.csv\"\n",
    "data = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_columns = data.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "categorical_columns = [\"Marital status\", \"Daytime/evening attendance\\t\", \"Gender\", \"Target\"]\n",
    "# Remove categorical columns from numerical processing\n",
    "numerical_columns = [col for col in numerical_columns if col not in categorical_columns]\n",
    "\n",
    "# Handle outliers in numerical columns using z-score (capping values beyond 3 standard deviations)\n",
    "data[numerical_columns] = data[numerical_columns].apply(\n",
    "    lambda x: x.clip(lower=x.mean() - 3 * x.std(), upper=x.mean() + 3 * x.std())\n",
    ")\n",
    "\n",
    "# Encoding categorical variables\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_columns[:-1], drop_first=True)\n",
    "\n",
    "# Standardize numerical columns for consistency across all classifiers\n",
    "scaler = StandardScaler()\n",
    "data_encoded[numerical_columns] = scaler.fit_transform(data_encoded[numerical_columns])\n",
    "\n",
    "# Apply PCA to retain 95% of variance\n",
    "X = data_encoded.drop(columns=[\"Target\"])\n",
    "y = data_encoded[\"Target\"]\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:02<00:00,  6.14s/it]\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"SVC\": SVC(probability=True), #enable probability estimates for SVC\n",
    "\n",
    "    \"LinearDiscriminant\": LinearDiscriminantAnalysis(),\n",
    "    \"QuadraticDiscriminant\": QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "\n",
    "    \"LogisticRegression\": LogisticRegression(multi_class=\"multinomial\", max_iter=500),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "}\n",
    "\n",
    "\n",
    "N = 20 #number of experiments\n",
    "prob_scores = []\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Map unique class labels to indices \n",
    "    class_labels = np.unique(y_train)\n",
    "    label_to_index = {label: idx for idx, label in enumerate(class_labels)}\n",
    "   \n",
    "    current_scores = {\"Experiment\": i+1}\n",
    "    for clf_name, clf in classifiers.items():\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            probs = clf.predict_proba(X_test) #!=clf.predict(X_test)\n",
    "        else:\n",
    "            # Platt scaling \n",
    "            calibrated_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=5)\n",
    "            calibrated_clf.fit(X_train, y_train)\n",
    "            probs = calibrated_clf.predict_proba(X_test)\n",
    "        \n",
    "        # Derive predictions directly from highest probability class\n",
    "        highest_prob_indices = probs.argmax(axis=1)\n",
    "        preds = [class_labels[idx] for idx in highest_prob_indices]\n",
    "\n",
    "        current_scores[f\"Label ({clf_name})\"] = preds\n",
    "        current_scores[f\"Prob ({clf_name})\"] = probs.tolist()\n",
    "\n",
    "    prob_scores.append(current_scores)\n",
    "\n",
    "prob_scores_df = pd.DataFrame(prob_scores)\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"Classifiers Benchmarking\", dataframe=prob_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Label (kNN)</th>\n",
       "      <th>Prob (kNN)</th>\n",
       "      <th>Label (DecisionTree)</th>\n",
       "      <th>Prob (DecisionTree)</th>\n",
       "      <th>Label (SVC)</th>\n",
       "      <th>Prob (SVC)</th>\n",
       "      <th>Label (LinearDiscriminant)</th>\n",
       "      <th>Prob (LinearDiscriminant)</th>\n",
       "      <th>Label (QuadraticDiscriminant)</th>\n",
       "      <th>...</th>\n",
       "      <th>Label (GaussianNB)</th>\n",
       "      <th>Prob (GaussianNB)</th>\n",
       "      <th>Label (LogisticRegression)</th>\n",
       "      <th>Prob (LogisticRegression)</th>\n",
       "      <th>Label (RandomForest)</th>\n",
       "      <th>Prob (RandomForest)</th>\n",
       "      <th>Label (Bagging)</th>\n",
       "      <th>Prob (Bagging)</th>\n",
       "      <th>Label (AdaBoost)</th>\n",
       "      <th>Prob (AdaBoost)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Graduate, Dropout, Graduate, Enrolled, Dropou...</td>\n",
       "      <td>[[0.0, 0.2, 0.8], [1.0, 0.0, 0.0], [0.2, 0.0, ...</td>\n",
       "      <td>[Graduate, Dropout, Dropout, Graduate, Enrolle...</td>\n",
       "      <td>[[0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [1.0, 0.0, ...</td>\n",
       "      <td>[Graduate, Dropout, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.05139014233908383, 0.2041335135569115, 0.7...</td>\n",
       "      <td>[Graduate, Dropout, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.024407995070653145, 0.17657345493775226, 0...</td>\n",
       "      <td>[Graduate, Dropout, Graduate, Graduate, Dropou...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Graduate, Dropout, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.03166207102080041, 0.17166944798393427, 0....</td>\n",
       "      <td>[Graduate, Dropout, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.04701450048507603, 0.1771524410484938, 0.7...</td>\n",
       "      <td>[Graduate, Dropout, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.11, 0.29, 0.6], [0.84, 0.1, 0.06], [0.04, ...</td>\n",
       "      <td>[Graduate, Dropout, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.2, 0.3, 0.5], [0.9, 0.1, 0.0], [0.0, 0.0, ...</td>\n",
       "      <td>[Graduate, Dropout, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.3246436768991152, 0.33478063848601713, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.2, 0.0, ...</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Graduate, Enroll...</td>\n",
       "      <td>[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.9270497907839012, 0.06899573491367075, 0.0...</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.9648554976432007, 0.011761313387859473, 0....</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Graduate, Dropou...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.9339876192247007, 0.008676454070069232, 0....</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.9778277114500894, 0.021282138075454045, 0....</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.98, 0.02, 0.0], [0.01, 0.02, 0.97], [0.07,...</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Graduate, Enroll...</td>\n",
       "      <td>[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Graduate, Dropou...</td>\n",
       "      <td>[[0.3546923202450973, 0.33118878407329394, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Graduate, Enrolled, Graduate, Dropout, Gradua...</td>\n",
       "      <td>[[0.0, 0.0, 1.0], [0.2, 0.4, 0.4], [0.0, 0.2, ...</td>\n",
       "      <td>[Enrolled, Graduate, Dropout, Enrolled, Gradua...</td>\n",
       "      <td>[[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, ...</td>\n",
       "      <td>[Enrolled, Dropout, Graduate, Dropout, Graduat...</td>\n",
       "      <td>[[0.34439752324303724, 0.3923070019837975, 0.2...</td>\n",
       "      <td>[Enrolled, Graduate, Graduate, Dropout, Gradua...</td>\n",
       "      <td>[[0.23143518410300457, 0.46519272467780187, 0....</td>\n",
       "      <td>[Graduate, Enrolled, Graduate, Enrolled, Gradu...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Graduate, Enrolled, Graduate, Dropout, Dropou...</td>\n",
       "      <td>[[0.16338651899054482, 0.10685622854946918, 0....</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Dropout, Graduat...</td>\n",
       "      <td>[[0.4304880675261239, 0.4088614674831752, 0.16...</td>\n",
       "      <td>[Graduate, Graduate, Graduate, Dropout, Gradua...</td>\n",
       "      <td>[[0.31, 0.29, 0.4], [0.22, 0.38, 0.4], [0.11, ...</td>\n",
       "      <td>[Enrolled, Enrolled, Graduate, Dropout, Gradua...</td>\n",
       "      <td>[[0.2, 0.5, 0.3], [0.3, 0.6, 0.1], [0.0, 0.2, ...</td>\n",
       "      <td>[Dropout, Graduate, Graduate, Dropout, Graduat...</td>\n",
       "      <td>[[0.3470712742220787, 0.32972338392155615, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[Graduate, Dropout, Enrolled, Graduate, Enroll...</td>\n",
       "      <td>[[0.0, 0.2, 0.8], [0.6, 0.0, 0.4], [0.2, 0.4, ...</td>\n",
       "      <td>[Graduate, Dropout, Enrolled, Graduate, Gradua...</td>\n",
       "      <td>[[0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 1.0, ...</td>\n",
       "      <td>[Graduate, Dropout, Enrolled, Graduate, Gradua...</td>\n",
       "      <td>[[0.031186375530215606, 0.06699681751865616, 0...</td>\n",
       "      <td>[Graduate, Dropout, Enrolled, Graduate, Gradua...</td>\n",
       "      <td>[[0.011121206936761344, 0.07372711292091684, 0...</td>\n",
       "      <td>[Graduate, Dropout, Enrolled, Graduate, Gradua...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Graduate, Graduate, Graduate, Graduate, Gradu...</td>\n",
       "      <td>[[0.015767301616952122, 0.04422554303051563, 0...</td>\n",
       "      <td>[Graduate, Dropout, Enrolled, Graduate, Gradua...</td>\n",
       "      <td>[[0.033226943372910954, 0.0890065461048606, 0....</td>\n",
       "      <td>[Graduate, Dropout, Enrolled, Graduate, Enroll...</td>\n",
       "      <td>[[0.06, 0.21, 0.73], [0.61, 0.23, 0.16], [0.24...</td>\n",
       "      <td>[Graduate, Dropout, Enrolled, Graduate, Gradua...</td>\n",
       "      <td>[[0.3, 0.3, 0.4], [0.5, 0.2, 0.3], [0.2, 0.6, ...</td>\n",
       "      <td>[Graduate, Dropout, Enrolled, Graduate, Gradua...</td>\n",
       "      <td>[[0.32018077019124597, 0.3261220063473578, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Graduate, Enrolled, Dropout, Graduate, Gradua...</td>\n",
       "      <td>[[0.0, 0.2, 0.8], [0.2, 0.4, 0.4], [0.4, 0.4, ...</td>\n",
       "      <td>[Dropout, Graduate, Dropout, Graduate, Dropout...</td>\n",
       "      <td>[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, ...</td>\n",
       "      <td>[Enrolled, Graduate, Dropout, Graduate, Dropou...</td>\n",
       "      <td>[[0.13086413511237013, 0.5668339782324031, 0.3...</td>\n",
       "      <td>[Graduate, Graduate, Dropout, Graduate, Dropou...</td>\n",
       "      <td>[[0.07553510120610431, 0.28704811250234297, 0....</td>\n",
       "      <td>[Enrolled, Graduate, Dropout, Graduate, Dropou...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Graduate, Graduate, Dropout, Graduate, Dropou...</td>\n",
       "      <td>[[0.07320939165191916, 0.22888894545667926, 0....</td>\n",
       "      <td>[Graduate, Graduate, Dropout, Graduate, Dropou...</td>\n",
       "      <td>[[0.1653643814707791, 0.26576458761634714, 0.5...</td>\n",
       "      <td>[Enrolled, Graduate, Dropout, Graduate, Dropou...</td>\n",
       "      <td>[[0.17, 0.42, 0.41], [0.11, 0.16, 0.73], [0.53...</td>\n",
       "      <td>[Enrolled, Graduate, Dropout, Graduate, Dropou...</td>\n",
       "      <td>[[0.3, 0.5, 0.2], [0.1, 0.2, 0.7], [0.4, 0.3, ...</td>\n",
       "      <td>[Dropout, Graduate, Dropout, Graduate, Dropout...</td>\n",
       "      <td>[[0.34406732267016604, 0.33552318019733374, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experiment                                        Label (kNN)  \\\n",
       "0           1  [Graduate, Dropout, Graduate, Enrolled, Dropou...   \n",
       "1           2  [Dropout, Graduate, Graduate, Graduate, Dropou...   \n",
       "2           3  [Graduate, Enrolled, Graduate, Dropout, Gradua...   \n",
       "3           4  [Graduate, Dropout, Enrolled, Graduate, Enroll...   \n",
       "4           5  [Graduate, Enrolled, Dropout, Graduate, Gradua...   \n",
       "\n",
       "                                          Prob (kNN)  \\\n",
       "0  [[0.0, 0.2, 0.8], [1.0, 0.0, 0.0], [0.2, 0.0, ...   \n",
       "1  [[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.2, 0.0, ...   \n",
       "2  [[0.0, 0.0, 1.0], [0.2, 0.4, 0.4], [0.0, 0.2, ...   \n",
       "3  [[0.0, 0.2, 0.8], [0.6, 0.0, 0.4], [0.2, 0.4, ...   \n",
       "4  [[0.0, 0.2, 0.8], [0.2, 0.4, 0.4], [0.4, 0.4, ...   \n",
       "\n",
       "                                Label (DecisionTree)  \\\n",
       "0  [Graduate, Dropout, Dropout, Graduate, Enrolle...   \n",
       "1  [Dropout, Graduate, Graduate, Graduate, Enroll...   \n",
       "2  [Enrolled, Graduate, Dropout, Enrolled, Gradua...   \n",
       "3  [Graduate, Dropout, Enrolled, Graduate, Gradua...   \n",
       "4  [Dropout, Graduate, Dropout, Graduate, Dropout...   \n",
       "\n",
       "                                 Prob (DecisionTree)  \\\n",
       "0  [[0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [1.0, 0.0, ...   \n",
       "1  [[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...   \n",
       "2  [[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, ...   \n",
       "3  [[0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 1.0, ...   \n",
       "4  [[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, ...   \n",
       "\n",
       "                                         Label (SVC)  \\\n",
       "0  [Graduate, Dropout, Graduate, Graduate, Dropou...   \n",
       "1  [Dropout, Graduate, Graduate, Graduate, Dropou...   \n",
       "2  [Enrolled, Dropout, Graduate, Dropout, Graduat...   \n",
       "3  [Graduate, Dropout, Enrolled, Graduate, Gradua...   \n",
       "4  [Enrolled, Graduate, Dropout, Graduate, Dropou...   \n",
       "\n",
       "                                          Prob (SVC)  \\\n",
       "0  [[0.05139014233908383, 0.2041335135569115, 0.7...   \n",
       "1  [[0.9270497907839012, 0.06899573491367075, 0.0...   \n",
       "2  [[0.34439752324303724, 0.3923070019837975, 0.2...   \n",
       "3  [[0.031186375530215606, 0.06699681751865616, 0...   \n",
       "4  [[0.13086413511237013, 0.5668339782324031, 0.3...   \n",
       "\n",
       "                          Label (LinearDiscriminant)  \\\n",
       "0  [Graduate, Dropout, Graduate, Graduate, Dropou...   \n",
       "1  [Dropout, Graduate, Graduate, Graduate, Dropou...   \n",
       "2  [Enrolled, Graduate, Graduate, Dropout, Gradua...   \n",
       "3  [Graduate, Dropout, Enrolled, Graduate, Gradua...   \n",
       "4  [Graduate, Graduate, Dropout, Graduate, Dropou...   \n",
       "\n",
       "                           Prob (LinearDiscriminant)  \\\n",
       "0  [[0.024407995070653145, 0.17657345493775226, 0...   \n",
       "1  [[0.9648554976432007, 0.011761313387859473, 0....   \n",
       "2  [[0.23143518410300457, 0.46519272467780187, 0....   \n",
       "3  [[0.011121206936761344, 0.07372711292091684, 0...   \n",
       "4  [[0.07553510120610431, 0.28704811250234297, 0....   \n",
       "\n",
       "                       Label (QuadraticDiscriminant)  ...  \\\n",
       "0  [Graduate, Dropout, Graduate, Graduate, Dropou...  ...   \n",
       "1  [Dropout, Graduate, Graduate, Graduate, Dropou...  ...   \n",
       "2  [Graduate, Enrolled, Graduate, Enrolled, Gradu...  ...   \n",
       "3  [Graduate, Dropout, Enrolled, Graduate, Gradua...  ...   \n",
       "4  [Enrolled, Graduate, Dropout, Graduate, Dropou...  ...   \n",
       "\n",
       "                                  Label (GaussianNB)  \\\n",
       "0  [Graduate, Dropout, Graduate, Graduate, Dropou...   \n",
       "1  [Dropout, Graduate, Graduate, Graduate, Dropou...   \n",
       "2  [Graduate, Enrolled, Graduate, Dropout, Dropou...   \n",
       "3  [Graduate, Graduate, Graduate, Graduate, Gradu...   \n",
       "4  [Graduate, Graduate, Dropout, Graduate, Dropou...   \n",
       "\n",
       "                                   Prob (GaussianNB)  \\\n",
       "0  [[0.03166207102080041, 0.17166944798393427, 0....   \n",
       "1  [[0.9339876192247007, 0.008676454070069232, 0....   \n",
       "2  [[0.16338651899054482, 0.10685622854946918, 0....   \n",
       "3  [[0.015767301616952122, 0.04422554303051563, 0...   \n",
       "4  [[0.07320939165191916, 0.22888894545667926, 0....   \n",
       "\n",
       "                          Label (LogisticRegression)  \\\n",
       "0  [Graduate, Dropout, Graduate, Graduate, Dropou...   \n",
       "1  [Dropout, Graduate, Graduate, Graduate, Dropou...   \n",
       "2  [Dropout, Graduate, Graduate, Dropout, Graduat...   \n",
       "3  [Graduate, Dropout, Enrolled, Graduate, Gradua...   \n",
       "4  [Graduate, Graduate, Dropout, Graduate, Dropou...   \n",
       "\n",
       "                           Prob (LogisticRegression)  \\\n",
       "0  [[0.04701450048507603, 0.1771524410484938, 0.7...   \n",
       "1  [[0.9778277114500894, 0.021282138075454045, 0....   \n",
       "2  [[0.4304880675261239, 0.4088614674831752, 0.16...   \n",
       "3  [[0.033226943372910954, 0.0890065461048606, 0....   \n",
       "4  [[0.1653643814707791, 0.26576458761634714, 0.5...   \n",
       "\n",
       "                                Label (RandomForest)  \\\n",
       "0  [Graduate, Dropout, Graduate, Graduate, Dropou...   \n",
       "1  [Dropout, Graduate, Graduate, Graduate, Dropou...   \n",
       "2  [Graduate, Graduate, Graduate, Dropout, Gradua...   \n",
       "3  [Graduate, Dropout, Enrolled, Graduate, Enroll...   \n",
       "4  [Enrolled, Graduate, Dropout, Graduate, Dropou...   \n",
       "\n",
       "                                 Prob (RandomForest)  \\\n",
       "0  [[0.11, 0.29, 0.6], [0.84, 0.1, 0.06], [0.04, ...   \n",
       "1  [[0.98, 0.02, 0.0], [0.01, 0.02, 0.97], [0.07,...   \n",
       "2  [[0.31, 0.29, 0.4], [0.22, 0.38, 0.4], [0.11, ...   \n",
       "3  [[0.06, 0.21, 0.73], [0.61, 0.23, 0.16], [0.24...   \n",
       "4  [[0.17, 0.42, 0.41], [0.11, 0.16, 0.73], [0.53...   \n",
       "\n",
       "                                     Label (Bagging)  \\\n",
       "0  [Graduate, Dropout, Graduate, Graduate, Dropou...   \n",
       "1  [Dropout, Graduate, Graduate, Graduate, Enroll...   \n",
       "2  [Enrolled, Enrolled, Graduate, Dropout, Gradua...   \n",
       "3  [Graduate, Dropout, Enrolled, Graduate, Gradua...   \n",
       "4  [Enrolled, Graduate, Dropout, Graduate, Dropou...   \n",
       "\n",
       "                                      Prob (Bagging)  \\\n",
       "0  [[0.2, 0.3, 0.5], [0.9, 0.1, 0.0], [0.0, 0.0, ...   \n",
       "1  [[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...   \n",
       "2  [[0.2, 0.5, 0.3], [0.3, 0.6, 0.1], [0.0, 0.2, ...   \n",
       "3  [[0.3, 0.3, 0.4], [0.5, 0.2, 0.3], [0.2, 0.6, ...   \n",
       "4  [[0.3, 0.5, 0.2], [0.1, 0.2, 0.7], [0.4, 0.3, ...   \n",
       "\n",
       "                                    Label (AdaBoost)  \\\n",
       "0  [Graduate, Dropout, Graduate, Graduate, Dropou...   \n",
       "1  [Dropout, Graduate, Graduate, Graduate, Dropou...   \n",
       "2  [Dropout, Graduate, Graduate, Dropout, Graduat...   \n",
       "3  [Graduate, Dropout, Enrolled, Graduate, Gradua...   \n",
       "4  [Dropout, Graduate, Dropout, Graduate, Dropout...   \n",
       "\n",
       "                                     Prob (AdaBoost)  \n",
       "0  [[0.3246436768991152, 0.33478063848601713, 0.3...  \n",
       "1  [[0.3546923202450973, 0.33118878407329394, 0.3...  \n",
       "2  [[0.3470712742220787, 0.32972338392155615, 0.3...  \n",
       "3  [[0.32018077019124597, 0.3261220063473578, 0.3...  \n",
       "4  [[0.34406732267016604, 0.33552318019733374, 0....  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "experiment = 1  \n",
    "classifier_name = \"LogisticRegression\"  \n",
    "\n",
    "prob_scores = prob_scores_df.loc[\n",
    "    prob_scores_df[\"Experiment\"]==experiment, f\"Prob ({classifier_name})\"\n",
    "].values\n",
    "\n",
    "print(sum(prob_scores[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
